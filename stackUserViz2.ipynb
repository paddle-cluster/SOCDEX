{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stackUserViz#\n",
    "*Now with more meta!*\n",
    "\n",
    "A Jupyter notebook for collecting, processing and visualizing user activity trajectories on Stack Exchange sites and their accompanying meta sites.\n",
    "\n",
    "- The first cell has settings and should be run before running any of the following cells\n",
    "- The second cell collects questions, answers, and comments from Stack Exchange main sites for a particular user. It produces one CSV file with all questions, answer and comments\n",
    "- The third cell collects questions, answers, and comments from Stack Exchange meta sites for a particular user. It produces one CSV file with all questions, answer and comments \n",
    "- The fourth cell collects reputation change events, orders the data, computes a running reputation score, and writes them to a CSV file\n",
    "- The fifth cell loads and processes the posting activity and reputation event files before summarizing and plotting the data. A short descriptive statistical summary is produced and saved as a text file and then a plot is generated showing posting activity as a stacked bar chart with questions, answers and comments, and reputation score as a line graph. Both datasets are aggregated and plotted monthly to show a continuous timeline that visualizes a user's activity on the platform as a trajectory\n",
    "\n",
    "To use these scripts, you will need a Stack Exchange API key that you put in a plain text file named stackApiKey.txt and put in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Always run this first!\n",
    "\n",
    "from stackapi import StackAPI\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import d6tstack.combine_csv\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from mpl_axes_aligner import align\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "# Choose community\n",
    "community = input(\"Which StackExchange community would you like to work with? \")\n",
    "\n",
    "# Choose a user\n",
    "userId = input(\"Which \"+community+\" user ID would you like to work with? \")\n",
    "\n",
    "keyfile = open('stackApiKey.txt', 'r') \n",
    "apiKey = keyfile.read() \n",
    "\n",
    "SITE = StackAPI(community, key=apiKey)\n",
    "SITE.page_size = 100\n",
    "SITE.max_pages = 10000\n",
    "\n",
    "stackLaunch = datetime(2008, 9, 22)\n",
    "\n",
    "################################\n",
    "# Edit collection settings here:\n",
    "# Set the period for collection\n",
    "startDate = stackLaunch\n",
    "#startDate = datetime(2008, 9, 22)\n",
    "\n",
    "endDate = datetime.today()\n",
    "#endDate = datetime(2020, 9, 22)\n",
    "\n",
    "# Set the length of each api call in days\n",
    "step = 365\n",
    "# Set a pause length in seconds to not violate the data cap on the API\n",
    "pause = 2\n",
    "################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect main site questions, answers and comments\n",
    "\n",
    "# Items to be dropped from datasets\n",
    "question_drop = ['owner_profile_image',\n",
    "                 'owner_link',\n",
    "                 'migrated_from_other_site_styling_tag_background_color',\n",
    "                 'migrated_from_other_site_styling_tag_foreground_color',\n",
    "                 'migrated_from_other_site_styling_link_color',\n",
    "                 'migrated_from_other_site_related_sites',\n",
    "                 'migrated_from_other_site_markdown_extensions',\n",
    "                 'migrated_from_other_site_launch_date',\n",
    "                 'migrated_from_other_site_open_beta_date',\n",
    "                 'migrated_from_other_site_site_state',\n",
    "                 'migrated_from_other_site_high_resolution_icon_url',\n",
    "                 'migrated_from_other_site_twitter_account',\n",
    "                 'migrated_from_other_site_favicon_url',\n",
    "                 'migrated_from_other_site_icon_url',\n",
    "                 'migrated_from_other_site_audience',\n",
    "                 'migrated_from_other_site_site_url',\n",
    "                 'migrated_from_other_site_api_site_parameter',\n",
    "                 'migrated_from_other_site_logo_url',\n",
    "                 'migrated_from_other_site_name',\n",
    "                 'migrated_from_other_site_site_type',\n",
    "                 'migrated_from_other_site_closed_beta_date',\n",
    "                 'migrated_from_other_site_aliases']\n",
    "comment_drop = ['owner_profile_image',\n",
    "                'owner_link',\n",
    "                'reply_to_user_profile_image',\n",
    "                'reply_to_user_link']\n",
    "answer_drop = ['owner_profile_image',\n",
    "               'owner_link']\n",
    "\n",
    "# Get questions\n",
    "questions = SITE.fetch('users/'+userId+'/questions', filter='withbody')\n",
    "df = pd.json_normalize(questions['items'],sep='_')\n",
    "\n",
    "# Stop if no data\n",
    "if len(df) < 2:\n",
    "    sys.exit('No activty')\n",
    "\n",
    "# Clean up\n",
    "df.drop(question_drop, inplace=True, axis=1, errors='ignore')\n",
    "if 'last_activity_date' in df.columns:\n",
    "    df['last_activity_date'] = pd.to_datetime(df['last_activity_date'], unit='s')\n",
    "if 'creation_date' in df.columns:\n",
    "    df['creation_date'] = pd.to_datetime(df['creation_date'], unit='s')\n",
    "if 'last_edit_date' in df.columns:\n",
    "    df['last_edit_date'] = pd.to_datetime(df['last_edit_date'], unit='s')\n",
    "if 'closed_date' in df.columns:\n",
    "    df['closed_date'] = pd.to_datetime(df['closed_date'], unit='s')\n",
    "if 'migrated_from_on_date' in df.columns:\n",
    "    df['migrated_from_on_date'] = pd.to_datetime(df['migrated_from_on_date'], unit='s')\n",
    "# Write processed trajectories to csv\n",
    "df['post_type']='question'\n",
    "df.to_csv(community+'_'+userId+'_questions.csv')\n",
    "print('Questions collected')\n",
    "\n",
    "# Get comments\n",
    "comments = SITE.fetch('users/'+userId+'/comments', filter='withbody')\n",
    "df = pd.json_normalize(comments['items'],sep='_')\n",
    "# Clean up\n",
    "df.drop(comment_drop, inplace=True, axis=1, errors='ignore')\n",
    "if 'creation_date' in df.columns:\n",
    "    df['creation_date'] = pd.to_datetime(df['creation_date'], unit='s')\n",
    "# Write processed trajectories to csv\n",
    "df['post_type']='comment'\n",
    "df.to_csv(community+'_'+userId+'_comments.csv')\n",
    "print('Comments collected')\n",
    "        \n",
    "# Get answers\n",
    "answers = SITE.fetch('users/'+userId+'/answers', filter='withbody')\n",
    "df = pd.json_normalize(answers['items'],sep='_')\n",
    "# Clean up\n",
    "df.drop(answer_drop, inplace=True, axis=1, errors='ignore')\n",
    "if 'last_activity_date' in df.columns:\n",
    "    df['last_activity_date'] = pd.to_datetime(df['last_activity_date'], unit='s')\n",
    "if 'creation_date' in df.columns:\n",
    "    df['creation_date'] = pd.to_datetime(df['creation_date'], unit='s')\n",
    "if 'last_edit_date' in df.columns:\n",
    "    df['last_edit_date'] = pd.to_datetime(df['last_edit_date'], unit='s')\n",
    "if 'community_owned_date' in df.columns:\n",
    "    df['community_owned_date'] = pd.to_datetime(df['community_owned_date'], unit='s')\n",
    "# Write processed trajectories to csv\n",
    "df['post_type']='answer'\n",
    "df.to_csv(community+'_'+userId+'_answers.csv')\n",
    "print('Answers collected')\n",
    "\n",
    "#Create a combined file\n",
    "files = [community+'_'+userId+'_questions.csv', \n",
    "         community+'_'+userId+'_comments.csv',\n",
    "         community+'_'+userId+'_answers.csv']\n",
    "combined = d6tstack.combine_csv.CombinerCSV(files).to_csv_combine(community+'_'+userId+'.csv')\n",
    "df = pd.read_csv(community+'_'+userId+'.csv', index_col=[0], dtype=object)\n",
    "df.drop({'filepath', 'filename'}, inplace=True, axis=1, errors='ignore')\n",
    "df.to_csv(community+'_'+userId+'.csv', index=False)\n",
    "for file in files:\n",
    "    os.remove(file)\n",
    "\n",
    "print('Main site posts collected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect meta site questions, answers and comments\n",
    "\n",
    "SITE = StackAPI('meta.'+community, key=apiKey)\n",
    "\n",
    "# Items to be dropped from datasets\n",
    "question_drop = ['owner_profile_image',\n",
    "                 'owner_link',\n",
    "                 'migrated_from_other_site_styling_tag_background_color',\n",
    "                 'migrated_from_other_site_styling_tag_foreground_color',\n",
    "                 'migrated_from_other_site_styling_link_color',\n",
    "                 'migrated_from_other_site_related_sites',\n",
    "                 'migrated_from_other_site_markdown_extensions',\n",
    "                 'migrated_from_other_site_launch_date',\n",
    "                 'migrated_from_other_site_open_beta_date',\n",
    "                 'migrated_from_other_site_site_state',\n",
    "                 'migrated_from_other_site_high_resolution_icon_url',\n",
    "                 'migrated_from_other_site_twitter_account',\n",
    "                 'migrated_from_other_site_favicon_url',\n",
    "                 'migrated_from_other_site_icon_url',\n",
    "                 'migrated_from_other_site_audience',\n",
    "                 'migrated_from_other_site_site_url',\n",
    "                 'migrated_from_other_site_api_site_parameter',\n",
    "                 'migrated_from_other_site_logo_url',\n",
    "                 'migrated_from_other_site_name',\n",
    "                 'migrated_from_other_site_site_type',\n",
    "                 'migrated_from_other_site_closed_beta_date',\n",
    "                 'migrated_from_other_site_aliases']\n",
    "comment_drop = ['owner_profile_image',\n",
    "                'owner_link',\n",
    "                'reply_to_user_profile_image',\n",
    "                'reply_to_user_link']\n",
    "answer_drop = ['owner_profile_image',\n",
    "               'owner_link']\n",
    "\n",
    "# Get questions\n",
    "questions = SITE.fetch('users/'+userId+'/questions', filter='withbody')\n",
    "df = pd.json_normalize(questions['items'],sep='_')\n",
    "# Clean up\n",
    "df.drop(question_drop, inplace=True, axis=1, errors='ignore')\n",
    "if 'last_activity_date' in df.columns:\n",
    "    df['last_activity_date'] = pd.to_datetime(df['last_activity_date'], unit='s')\n",
    "if 'creation_date' in df.columns:\n",
    "    df['creation_date'] = pd.to_datetime(df['creation_date'], unit='s')\n",
    "if 'last_edit_date' in df.columns:\n",
    "    df['last_edit_date'] = pd.to_datetime(df['last_edit_date'], unit='s')\n",
    "if 'closed_date' in df.columns:\n",
    "    df['closed_date'] = pd.to_datetime(df['closed_date'], unit='s')\n",
    "if 'migrated_from_on_date' in df.columns:\n",
    "    df['migrated_from_on_date'] = pd.to_datetime(df['migrated_from_on_date'], unit='s')\n",
    "# Write processed trajectories to csv\n",
    "df['post_type']='question'\n",
    "df.to_csv(community+'_'+userId+'_questions.csv')\n",
    "print('Questions collected')\n",
    "\n",
    "# Get comments\n",
    "comments = SITE.fetch('users/'+userId+'/comments', filter='withbody')\n",
    "df = pd.json_normalize(comments['items'],sep='_')\n",
    "# Clean up\n",
    "df.drop(comment_drop, inplace=True, axis=1, errors='ignore')\n",
    "if 'creation_date' in df.columns:\n",
    "    df['creation_date'] = pd.to_datetime(df['creation_date'], unit='s')\n",
    "# Write processed trajectories to csv\n",
    "df['post_type']='comment'\n",
    "df.to_csv(community+'_'+userId+'_comments.csv')\n",
    "print('Comments collected')\n",
    "        \n",
    "# Get answers\n",
    "answers = SITE.fetch('users/'+userId+'/answers', filter='withbody')\n",
    "df = pd.json_normalize(answers['items'],sep='_')\n",
    "# Clean up\n",
    "df.drop(answer_drop, inplace=True, axis=1, errors='ignore')\n",
    "if 'last_activity_date' in df.columns:\n",
    "    df['last_activity_date'] = pd.to_datetime(df['last_activity_date'], unit='s')\n",
    "if 'creation_date' in df.columns:\n",
    "    df['creation_date'] = pd.to_datetime(df['creation_date'], unit='s')\n",
    "if 'last_edit_date' in df.columns:\n",
    "    df['last_edit_date'] = pd.to_datetime(df['last_edit_date'], unit='s')\n",
    "if 'community_owned_date' in df.columns:\n",
    "    df['community_owned_date'] = pd.to_datetime(df['community_owned_date'], unit='s')\n",
    "# Write processed trajectories to csv\n",
    "df['post_type']='answer'\n",
    "df.to_csv(community+'_'+userId+'_answers.csv')\n",
    "print('Answers collected')\n",
    "\n",
    "#Create a combined file\n",
    "files = [community+'_'+userId+'_questions.csv', \n",
    "         community+'_'+userId+'_comments.csv',\n",
    "         community+'_'+userId+'_answers.csv']\n",
    "\n",
    "combined = d6tstack.combine_csv.CombinerCSV(files).to_csv_combine('meta_'+community+'_'+userId+'.csv')\n",
    "df = pd.read_csv('meta_'+community+'_'+userId+'.csv', index_col=[0], dtype=object)\n",
    "df.drop({'filepath', 'filename'}, inplace=True, axis=1, errors='ignore')\n",
    "df.to_csv('meta_'+community+'_'+userId+'.csv', index=False)\n",
    "\n",
    "#Remove temporary files\n",
    "for file in files:\n",
    "    os.remove(file)\n",
    "    \n",
    "#Remove combined file if number of rows is below threshold    \n",
    "if len(df) < 10:\n",
    "    os.remove('meta_'+community+'_'+userId+'.csv')\n",
    "    print('Too little meta activity')\n",
    "else:\n",
    "    print('meta site posts collected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect reputation events\n",
    "\n",
    "stepDate = startDate + timedelta(days=step)\n",
    "\n",
    "# Collect reputation events\n",
    "while stepDate < endDate:\n",
    "    events = SITE.fetch('users/'+userId+'/reputation-history', fromdate=startDate, todate=stepDate)\n",
    "    df = pd.json_normalize(events['items'],sep='_')\n",
    "    df.to_csv('temp_'+startDate.strftime('%Y-%m-%d')+'_'+stepDate.strftime('%Y-%m-%d')+'.csv')\n",
    "    time.sleep(pause)\n",
    "    print(str(startDate)+' to '+str(stepDate)+' collected')\n",
    "    startDate = stepDate + timedelta(days=1)\n",
    "    stepDate = startDate + timedelta(days=step)\n",
    "\n",
    "else:\n",
    "    events = SITE.fetch('users/'+userId+'/reputation-history', fromdate=startDate, todate=endDate)\n",
    "    df = pd.json_normalize(events['items'],sep='_')\n",
    "    df.to_csv('temp_'+startDate.strftime('%Y-%m-%d')+'_'+stepDate.strftime('%Y-%m-%d')+'.csv')\n",
    "    print(str(startDate)+' to '+str(endDate)+' collected')\n",
    "\n",
    "# Stitch the yearly files together\n",
    "files = list(glob.glob('temp_*.csv'))\n",
    "li = []\n",
    "for filename in files:\n",
    "    df1 = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df1)\n",
    "df = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "# Clean up temporary files\n",
    "files = list(glob.glob('temp_*.csv'))\n",
    "for file in files:\n",
    "    os.remove(file)\n",
    "\n",
    "# Sort by creation_date or remove files if empty\n",
    "if df.empty:\n",
    "    print('No reputation events')\n",
    "\n",
    "else:\n",
    "    df = df.sort_values(by = 'creation_date') \n",
    "    # Create nomalized timestamp timeline\n",
    "    df['time_delta'] = df['creation_date'].diff()\n",
    "    # Calculate cumulative sum of reputation\n",
    "    df['days'] = df['time_delta'].cumsum() / 86400\n",
    "    df['reputation'] = df['reputation_change'].cumsum()\n",
    "    # Convert timestamps to datetime\n",
    "    df['creation_date'] = pd.to_datetime(df['creation_date'], unit='s')\n",
    "    # Write processed reputation events to csv\n",
    "    df.to_csv(community+'_'+userId+'_reputation.csv')\n",
    "    print('Reputation events collected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import user data and visualize it\n",
    "\n",
    "if os.path.isfile(community+'_'+userId+'.csv'):\n",
    "    df = pd.read_csv(community+'_'+userId+'.csv', parse_dates=['creation_date'])\n",
    "else:\n",
    "    sys.exit('No activty')\n",
    "\n",
    "if os.path.isfile('meta_'+community+'_'+userId+'.csv'):\n",
    "    mdf = pd.read_csv('meta_'+community+'_'+userId+'.csv')\n",
    "    mdf = pd.read_csv('meta_'+community+'_'+userId+'.csv', parse_dates=['creation_date'])\n",
    "\n",
    "if os.path.isfile(community+'_'+userId+'_reputation.csv'):\n",
    "    repdf = pd.read_csv(community+'_'+userId+'_reputation.csv', parse_dates=['creation_date'])\n",
    "\n",
    "# Descriptive stats\n",
    "date = df['creation_date']\n",
    "since = date.min()\n",
    "print('Active since: '+str(since))\n",
    "\n",
    "if os.path.isfile(community+'_'+userId+'_reputation.csv'):\n",
    "    rep = repdf['reputation']\n",
    "    max_rep = rep.max()\n",
    "    print('Reputation: '+str(max_rep))\n",
    "\n",
    "posts = df.shape[0]\n",
    "print('Posts on '+community+': '+str(posts))\n",
    "\n",
    "if os.path.isfile('meta_'+community+'_'+userId+'.csv'):\n",
    "    mposts = mdf.shape[0]\n",
    "    print('Posts on meta.'+community+': '+str(mposts))\n",
    "\n",
    "dfv = df['post_type'].value_counts()\n",
    "print('Post types on '+community+':')\n",
    "print(dfv)\n",
    "\n",
    "if os.path.isfile('meta_'+community+'_'+userId+'.csv'):\n",
    "    mdfv = mdf['post_type'].value_counts()\n",
    "    print('Post types on meta.'+community+':')\n",
    "    print(mdfv)\n",
    "\n",
    "# Plot activity and reputation on a single figure\n",
    "\n",
    "# Process main posting data\n",
    "df['month_year'] = pd.to_datetime(df['creation_date']).map(lambda dt: dt.replace(day=1))\n",
    "df['month_year'] = pd.to_datetime(df['month_year']).dt.date\n",
    "df1 = df.groupby(['month_year', 'post_type'])['creation_date'].count().reset_index(name='count')\n",
    "df1 = df1.pivot(index='month_year', columns='post_type', values='count')\n",
    "df1.index = pd.to_datetime(df1.index)\n",
    "df1 = df1.resample('MS').asfreq().fillna(0)\n",
    "df1 = df1.reset_index()\n",
    "df1.month_year = df1.month_year.dt.date\n",
    "df1.month_year = df1.month_year.astype('object')\n",
    "df1[['answer', 'comment', 'question']] = df1[['answer', 'comment', 'question']].astype('int64')\n",
    "df1.rename(columns={'answer': 'Answers', 'comment': 'Comments', 'question': 'Questions'}, inplace=True)\n",
    "\n",
    "# Process meta posting data\n",
    "if os.path.isfile('meta_'+community+'_'+userId+'.csv'):\n",
    "    mdf['month_year'] = pd.to_datetime(mdf['creation_date']).map(lambda dt: dt.replace(day=1))\n",
    "    mdf['month_year'] = pd.to_datetime(mdf['month_year']).dt.date\n",
    "    mdf1 = mdf.groupby(['month_year', 'post_type'])['creation_date'].count().reset_index(name='count')\n",
    "    mdf1 = mdf1.pivot(index='month_year', columns='post_type', values='count')\n",
    "    mdf1.index = pd.to_datetime(mdf1.index)\n",
    "    mdf1 = mdf1.resample('MS').asfreq().fillna(0)\n",
    "    mdf1 = mdf1.reset_index()\n",
    "    mdf1.month_year = mdf1.month_year.dt.date\n",
    "    mdf1.month_year = mdf1.month_year.astype('object')\n",
    "    if 'answer' not in mdf1:\n",
    "        mdf1['answer'] = 0\n",
    "    if 'comment' not in mdf1:\n",
    "        mdf1['comment'] = 0\n",
    "    if 'question' not in mdf1:\n",
    "        mdf1['question'] = 0\n",
    "    mdf1[['answer', 'comment', 'question']] = mdf1[['answer', 'comment', 'question']].astype('int64')\n",
    "    mdf1.rename(columns={'answer': 'meta.Answers', 'comment': 'meta.Comments', 'question': 'meta.Questions'}, inplace=True)\n",
    "    mdf1['Meta Posts'] = mdf1['meta.Answers'] + mdf1['meta.Comments'] + mdf1['meta.Questions']\n",
    "\n",
    "# Process reputation data\n",
    "if os.path.isfile(community+'_'+userId+'_reputation.csv'):\n",
    "    repdf1 = repdf[['creation_date', 'reputation']].copy()\n",
    "    repdf1['month_year'] = pd.to_datetime(repdf1['creation_date']).map(lambda dt: dt.replace(day=1))\n",
    "    repdf1['month_year'] = pd.to_datetime(repdf1['month_year']).dt.date\n",
    "    repdf1 = repdf1.groupby(['month_year'], sort=False)['reputation'].max()\n",
    "    repdf1.index = pd.to_datetime(repdf1.index)\n",
    "    repdf1 = repdf1.resample('MS').asfreq().fillna(method='ffill')\n",
    "    repdf1 = repdf1.reset_index()\n",
    "    repdf1.month_year = repdf1.month_year.dt.date\n",
    "    repdf1.month_year = repdf1.month_year.astype('object')\n",
    "    repdf1['reputation'] = repdf1['reputation'].astype('int64')\n",
    "    repdf1.rename(columns={'reputation': 'Reputation'}, inplace=True)\n",
    "\n",
    "# Create a merged dataframe, but ignore meta if empty\n",
    "if not os.path.isfile('meta_'+community+'_'+userId+'.csv'):\n",
    "    merged = df1.copy()\n",
    "else:\n",
    "    merged = pd.merge(df1, mdf1, on=['month_year'], how='outer')\n",
    "    merged = pd.merge(merged, repdf1, on=['month_year'], how='outer')\n",
    "    \n",
    "merged.month_year = pd.to_datetime(merged.month_year)\n",
    "merged = merged.sort_values('month_year').reset_index(drop=True)\n",
    "\n",
    "# Plot the figures\n",
    "fig, ax = plt.subplots(figsize = (15,4))\n",
    "ax.axhline(0, color='#EEEEEE')\n",
    "\n",
    "if not os.path.isfile('meta_'+community+'_'+userId+'.csv'):\n",
    "    ax1 = merged[['Answers', 'Comments', 'Questions']].plot(kind='bar', legend=False, stacked=True, color=['#284E60', '#F99B45', '#63AAC0'], width=0.8, ax=ax)\n",
    "    ax2 = merged['Reputation'].plot(legend=False, secondary_y=True, color='#D95980', linewidth=2, ax=ax)\n",
    "    for ax in (ax1, ax2):\n",
    "        ax.spines[\"top\"].set_visible(False)    \n",
    "        ax.spines[\"bottom\"].set_visible(False)    \n",
    "        ax.spines[\"right\"].set_visible(False)    \n",
    "        ax.spines[\"left\"].set_visible(False)\n",
    "        ax.tick_params(bottom=False, left=False, right=False)\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.xaxis.grid(False)\n",
    "        ax.ticklabel_format(useOffset=False, style='plain', axis='y')\n",
    "    # Axis\n",
    "    align.yaxes(ax1, 0.0, ax2, 0.0, 0.1)\n",
    "    max_value = merged.index.max()\n",
    "    min_value = merged.index.min()\n",
    "    number_of_steps = 5\n",
    "    l = np.arange(min_value, max_value+1, number_of_steps)\n",
    "    ax.set(xticks=l, xticklabels=l)\n",
    "    ax1.tick_params(axis='x', pad=-20)\n",
    "    ax1.yaxis.grid(True, color='#EEEEEE')\n",
    "    # Labels\n",
    "    ax.set_xlabel('Month of Participation', labelpad=10, color='#333333')\n",
    "    ax1.set_ylabel('Posts', labelpad=15, color='#333333')\n",
    "    ax2.set_ylabel('Reputation Score', labelpad=15, color='#333333') \n",
    "    plt.title('Participation trajectory for '+community+' user '+userId, fontsize=15, color='#333333', loc='left', pad=5)\n",
    "    # Legend\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    leg = ax.legend(lines1 + lines2, labels1 + labels2, frameon=False, loc='upper right', ncol=5, bbox_to_anchor=(1.1, 1.1))\n",
    "    for text in leg.get_texts():\n",
    "        plt.setp(text, color = '#333333')\n",
    "        \n",
    "else:\n",
    "    ax1 = merged[['Answers', 'Comments', 'Questions']].plot(kind='bar', legend=False, stacked=True, color=['#284E60', '#F99B45', '#63AAC0'], width=0.8, ax=ax)\n",
    "    ax2 = merged['Meta Posts'].plot(legend=False, color='#2a9d8f', linewidth=2, ax=ax)\n",
    "    ax3 = merged['Reputation'].plot(legend=False, secondary_y=True, color='#D95980', linewidth=2, ax=ax)\n",
    "    for ax in (ax1, ax2, ax3):\n",
    "        ax.spines[\"top\"].set_visible(False)    \n",
    "        ax.spines[\"bottom\"].set_visible(False)    \n",
    "        ax.spines[\"right\"].set_visible(False)    \n",
    "        ax.spines[\"left\"].set_visible(False)\n",
    "        ax.tick_params(bottom=False, left=False, right=False)\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.xaxis.grid(False)\n",
    "        ax.ticklabel_format(useOffset=False, style='plain', axis='y')\n",
    "    \n",
    "    # Axis\n",
    "    align.yaxes(ax1, 0.0, ax3, 0.0, 0.1)\n",
    "    max_value = merged.index.max()\n",
    "    min_value = merged.index.min()\n",
    "    number_of_steps = 5\n",
    "    l = np.arange(min_value, max_value+1, number_of_steps)\n",
    "    ax.set(xticks=l, xticklabels=l)\n",
    "    ax1.tick_params(axis='x', pad=-20)\n",
    "    ax1.yaxis.grid(True, color='#EEEEEE')\n",
    "    # Labels\n",
    "    ax.set_xlabel('Month of Participation', labelpad=10, color='#333333')\n",
    "    ax1.set_ylabel('Posts', labelpad=15, color='#333333')\n",
    "    ax3.set_ylabel('Reputation Score', labelpad=15, color='#333333') \n",
    "    plt.title('Participation trajectory for '+community+' user '+userId, fontsize=15, color='#333333', loc='left', pad=5)\n",
    "    # Legend\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines3, labels3 = ax3.get_legend_handles_labels()\n",
    "    leg = ax.legend(lines1 + lines3, labels1 + labels3, frameon=False, loc='upper right', ncol=5, bbox_to_anchor=(1.1, 1.1))\n",
    "    for text in leg.get_texts():\n",
    "        plt.setp(text, color = '#333333')\n",
    "\n",
    "# Save and show figure\n",
    "save = plt.gcf()\n",
    "plt.show()\n",
    "save.savefig(community+'_'+userId+'.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

